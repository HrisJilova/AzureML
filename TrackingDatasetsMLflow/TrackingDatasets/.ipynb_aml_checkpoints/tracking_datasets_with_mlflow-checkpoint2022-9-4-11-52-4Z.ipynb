{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Prerequisites to run this notebook"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have the dependencies for this notebook\r\n",
        "#%pip install -r logging_model_with_mlflow.txt"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\r\n",
        "import mlflow\r\n",
        "import mlflow.azureml\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "from mlflow.tracking import MlflowClient\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from azureml.core import Dataset\r\n",
        "#from azureml.data.dataset_factory import DataType\r\n",
        "import tempfile\r\n",
        "\r\n",
        "print(\"SDK version:\", azureml.core.VERSION)\r\n",
        "print(\"MLflow version:\", mlflow.version.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.44.0\nMLflow version: 1.28.0\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name =\"TrackDatasets\"\r\n",
        "experiment=mlflow.set_experiment(experiment_name)\r\n",
        "experiment_id=experiment.experiment_id\r\n",
        "\r\n",
        "# Create an experiment with a name that is unique and case sensitive.\r\n",
        "client = MlflowClient()\r\n",
        "#experiment_id = client.create_experiment(experiment_name)\r\n",
        "client.set_experiment_tag(experiment_id, \"exper ver\", \"1\")\r\n",
        "\r\n",
        "\r\n",
        "# Fetch experiment metadata information\r\n",
        "experiment = client.get_experiment(experiment_id)\r\n",
        "print(\"Name: {}\".format(experiment.name))\r\n",
        "print(\"Experiment_id: {}\".format(experiment.experiment_id))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: TrackDatasets\nExperiment_id: 1ae4018f-adf2-4b54-ae2c-ad04fe6ddca0\nArtifact Location: \nTags: {'exper ver': '1'}\nLifecycle_stage: active\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\r\n",
        "df = pd.read_csv(file_url)\r\n",
        "df[\"thal\"] = df[\"thal\"].astype(\"category\").cat.codes"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "    df.drop(\"target\", axis=1), df[\"target\"], test_size=0.3\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two main approaches to track the datasets: the first one is to save a copy of your input data:\r\n",
        "\r\n",
        "```\r\n",
        "    with tempfile.TemporaryDirectory() as tmp:\r\n",
        "        path = 'saveDatasetVer/train_dataset.csv'  #path where you whant to save your dataset used for training \r\n",
        "        X_train.to_csv(path)\r\n",
        "        mlflow.log_artifacts(tmp)\r\n",
        "```\r\n",
        "\r\n",
        "In case the dataset is too big you can log the path to the dataset as a parameter: \r\n",
        "\r\n",
        "```\r\n",
        "    mlflow.log_param('dsPathМ', file_url )   #track the pointer to the data\r\n",
        "\r\n",
        "```\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\r\n",
        "from xgboost import XGBClassifier\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from mlflow.models import infer_signature\r\n",
        "\r\n",
        "with mlflow.start_run():  \r\n",
        "    mlflow.xgboost.autolog(log_models=True,log_input_examples=True,log_model_signatures=True,registered_model_name='DatastetsModel')\r\n",
        "\r\n",
        "    model = XGBClassifier(use_label_encoder=False, eval_metric=\"auc\")\r\n",
        "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\r\n",
        "    y_pred = model.predict(X_test)\r\n",
        "\r\n",
        "    accuracy = accuracy_score(y_test, y_pred)\r\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\r\n",
        "\r\n",
        "    mlflow.log_param('dsPathМ', file_url )   #track the pointer to the data\r\n",
        "\r\n",
        "    with tempfile.TemporaryDirectory() as tmp:\r\n",
        "        path = 'saveDatasetVer/train_dataset.csv'  #path where you whant to save your dataset used for training \r\n",
        "        X_train.to_csv(path)\r\n",
        "        mlflow.log_artifacts(tmp)\r\n",
        "\r\n",
        "    signature = infer_signature(X_test, y_test)\r\n",
        "    mlflow.xgboost.log_model(model, \"classifier\", signature=signature)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Registered model 'DatastetsModel' already exists. Creating a new version of this model...\n2022/10/04 11:03:19 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: DatastetsModel, version 2\nCreated version '2' of model 'DatastetsModel'.\n/anaconda/envs/azureml_py38/lib/python3.8/site-packages/mlflow/models/signature.py:130: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  outputs = _infer_schema(model_output) if model_output is not None else None\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**log_models** -  If True, trained models are logged as MLflow model artifacts. If False, trained models are not logged. Input examples and model signatures, which are attributes of MLflow models, are also omitted when log_models is False.  \r\n",
        "\r\n",
        "\r\n",
        "**registered_model_name** – If given, each time a model is trained, it is registered as a new model version of the registered model with this name. The registered model is created if it does not already exist.    \r\n",
        "\r\n",
        "**log_input_examples** – If True, input examples from training datasets are collected and logged along with XGBoost model artifacts during training. If False, input examples are not logged. Note: Input examples are MLflow model attributes and are only collected if log_models is also True\r\n",
        "\r\n",
        "**log_model_signatures** – If True, ModelSignatures describing model inputs and outputs are collected and logged along with XGBoost model artifacts during training. If False, signatures are not logged. Note: Model signatures are MLflow model attributes and are only collected if log_models is also True.\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}